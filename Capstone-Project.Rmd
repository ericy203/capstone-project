---
title: "NFL Project"
author: "Eric Young"
date: "11/19/2019"
output:
  pdf_document: default
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Predicting the Longevity of NFL Players

The goal of this project is to predict which players from NCAA College Football will be drafted into the NFL. I will use data of the college players to predict which players will be drafted into the NFL. The success criteria will be based on TRUE or FALSE, TRUE if the player is drafted into the NFL, they were succesful or FALSE the player was not drafted into the NFL or they were unsuccessful. 

I will start the prediction from their Freshman year through their Senior year. Performance data from the NFL data set will not be used for predictions. I will be using data from the NCAA (via the CollegeballR package) to determine if a player will be drafted in to the NFL.  

## Potential Clients

The client for this project would be the NFL teams, players, and agents. The information provided could help the NFL teams understand which teams generally have the most tallent. It will also help them to see what teams may have hidden talent. This project could benefit players in High School deciding which schools can best help them get to the NFL. For current college players the project can help them know their likelyhood of gettign into the NFL. For agents the project will help them decide which college teams they should go after to get players drafted into the NFL. 

#### Libraries used

Below are the libraries which I will be using in the capstone project. The collegeballR package is from GitHub and you will need to use devtools to install it.

```{r results = "hide", message = FALSE, warning=FALSE}
library(devtools)
library(readr) 
library(dplyr)
library(tidyr)
library(ggplot2)
library(xtable)
library(collegeballR)
library(knitr)
library(kableExtra)
library(ROCR)
library(pROC)
library(caTools)
library(texreg)
library(margins)
```
### NFL Data Set Import
Set the working directory and read in the Basic Stats file

```{r}
basic_stats <- read.csv("nflstatistics/basic_stats_clean.csv", header = TRUE, stringsAsFactors = FALSE)
```

```{r echo=FALSE}
kable(basic_stats[1:5, c("Age","Name","College","Experience","Height..inches.","Weight..lbs.")]) %>%
  kable_styling(latex_options = c("striped"))
```

### NCAA Data Set Import
We need to import the collegedf data set which has all of our NCAA player and team information.
```{r}
collegedf <- read.csv("./nflstatistics/college_data.csv", header = TRUE, stringsAsFactors = FALSE)
```

```{r echo=FALSE}
kable(collegedf[1:5, c("Player","team_name","Yr","Pos","GP","GS","G","Rush.Attempts","Rush.Net.Yards","Rush.YdsGained")]) %>%
  kable_styling(latex_options = c("striped", "scale_down"))
```

### NFL & NCAA Joined Data Set Import
```{r}
college_draft <- read.csv("./nflstatistics/college_draft.csv")
```

```{r echo=FALSE}
kable(college_draft[1:5, c("Player","Yr","Pos","GP","GS","GNS","Height..inches.","Weight..lbs.","was_drafted","team_name")]) %>%
  kable_styling(latex_options = c("striped"))
```


### Source of data

There are two data sets which I will be using for this capstone project. The first source dataset is from Kaggle and is named [NFL Statistics](https://www.kaggle.com/kendallgillies/nflstatistics). The second source comes the NCAA (pulled using a package created by Meyappan called [collegeballR](https://github.com/meysubb/collegeballR)).

When trying to tie team_stats to the data frame I found a bug in the team_stats.R where it was not looking up sport and giving an error. I had to fork the original package into [my repository](https://github.com/ericy203/collegeballR/) and edit the code. 

The original size of the basic_stats data frame is 17,172 rows and 17 columns. Since the data from the collegeballR package is only available from 2014 - 2018. I will only be covering the years between 2014 and 2017 as the 2018 data was not available yet at the time of downloading.

The variables I will use to predict are:

* College Team
* Position
* Games Played - How many games the player played in the season
* Games Started - How many games a player started
* Games Not Started - Games Played - Games started = Games Not Started
* Rush Attempts
* Rush Net Yards
* Rush Yards Gained
* Height
* Weight
* Experience
* Year - Freshman, Sophmore, Junior, Senior



#### Deliverables

The deliverables for this project will be:

* NFL_Project.R - this is the file with all of the code
* Capstone-Project.Rmd - this file has the analysis
* Output of project file as a PDF
* Deck of slides with insights and plots



### Basic Stats (NFL Data)

Let's check the data and basic information on basic_stats
```{r}
basic_stats <- separate(basic_stats, Birth.Place, c("City", "State"), sep = ",")
```

-xtable turn summary into a table
```{r results='asis'}
kable(summary(basic_stats[ , 1:7])) %>%
  kable_styling(latex_options = c("striped", "scale_down"))
kable(summary(basic_stats[ , 8:14])) %>%
  kable_styling(latex_options = c("striped", "scale_down"))
kable(summary(basic_stats[ , 15:18])) %>%
  kable_styling(latex_options = c("striped"))
```


## Clean College Ball R
The CollegeBallR package was available on Github but we had many issues using this data set. So we had to pull the data directly from the NCAA website and create our own data frame. The data frame had the below issues which needed to be fixed.

1. Pull all combinations for each team and season from the NCAA website.
2. Dropped all players which didn't have a position
 - The players didn't have a position because they didn't play that season.
3. Dropped all years that were N/A
4. Relabled positions and statndardized them.
 - For example WILL is a type of Line Backer so I relabled them as LB
5. Created csv to be be used later in the project.



## Create and Clean College_draft
To create the data frame College_draft I did a left join on the NCAA and NFL data frames.
By creating this data frame we were able to analyze how many players were drafted from college into the NFL and from which teams. However, there were some data problems that I needed to fix which I will list below.

1. Create logical variable of TRUE or FALSE if the player was drafted into the NFL.
2. Sanitized the column names and stripped out invalid characters.
3. Remove comma from rushing yards variables.
4. Change games played and games started variables to numeric.
5. Created a new variable games not started.
6. Dropped all NULL positions from the data set.
7. Created a cleaned version of the csv to be be used later in the project.

## NFL Plots
One question that may be asked while reviewing NFL player data is are the players bigger now than they were when the NFL started. In the chart below we see that players now weigh aproximately 60 to 70 lbs more than in the 1920's. From 1920 to around 2000 there was a steady increase in the weight of the players. Since 200 the average weight of players has stayed about the same. The below chart shows the mean weight of football players has increased from 1920 to 2018.
```{r}
ggplot(basic_stats) +
  aes(x = as.numeric(start_year), y = Weight..lbs.) +
  geom_point() +
  geom_smooth() +
  labs(x = "Year", y = "Weight in Lbs")
```

Another question that may be asked is are player taller today then they were when the NFL started. The answer is yes, the average height in 1920 was about 70 inches and dramatically increased until about 1970 where players are an average height of 74 inches. This chart shows the average height in the NFL hit its peak in the 1970s and is close to the same today.

What is interesting about the chart below is all of the plots are evely placed and staggered. The reason for this is when a team records the height of a player they don't measue in quarter or half of an inch they will round up to the nearest inch.
```{r, warning=FALSE, message=FALSE}
ggplot(basic_stats) +
  aes(x = as.numeric(start_year), y = Height..inches.) +
  geom_point() +
  geom_smooth() +
  labs(x = "Year", y = "Height in Inches")
```

The density plot below shows the difference in height between all of the NFL teams. The most common height in the NFl seems to be around 75 inches. Players who are drafted and play in the NFL are usually between 70 and 77 inches in height. This means if you are below 70 inches it is still possible to be drafted but you'll have to be an excellent athlete to make it into the NFL. On the other hand there are a few players who are in the NFL at 80 inches or about 6 feet 8 inches. 
```{r, warning=FALSE}
ggplot(basic_stats, aes(Height..inches., fill = Current.Team)) +
         geom_density() +
  facet_wrap(~Current.Team) +
  guides(fill = "none") +
  labs(x = "Height in Inches")
```

The box and whisker plot below shows us the lowest observation, highest oservation, the four quartiles, and average years of experience for each NFL team. For many of the teams the first quartile is 0 meaning 1 in 4 players are rookies. There are 19 teams with 3 years of median experience and 12 teams with 2 years of median experience. This means most players in the NFL have between 2 and 3 years of experience. It looks like 75% of players will retire between 5 and 7 years of playing in the NFL. The New Orleans Saints have the highest observation of years of experience and third quartile of player retiring. Almost every team has outliers and what is surprising is some players have over 15 years in the NFL.
```{r}
ggplot(basic_stats, aes(Current.Team, Experience)) +
  geom_boxplot() +
  labs(x = "NFL Teams", y = "Years of Experience") +
  coord_flip()
```


## NCAA Plots
This bar plot shows the distribution of players by year, season and the progression of players from Freshman, Sophmore, Junior, and Senior by year. The amount of players progressing from one year to the next is never the same for any of the years. Senior year is always lower than the previous Junior year. This could be because of players moving into the NFL before completeing their Senior year. The increase of players in the Sophmore and Junior years could be caused by players transferring from Junior Colleges. 
```{r}
ggplot(collegedf, aes(season, fill = Yr, group = Yr)) +
  geom_bar(position = "dodge")
```

The below chart shows by the number of attempts how many yards are lost. The natural thought would be the more rushing attempts a player has the more likely they are to lose yardage. To an extent this is true. However we see in the scatter plot that this isn't exactly true. We can see players who have rushed nearly 400 times and have only lost around 50 yards. Then there is another group who have rushed far less times but have lost a lot more yardage.
```{r, warning=FALSE}
ggplot(collegedf, aes(x = `Rush.Attempts`, y = `Rush.YdsLost`)) +
  geom_point()
```

The below chart shows by year how many players played each position and displays them by year. We can see that there is variation for every position from year to year. It is not uncommon for a player to switch positions, for example a wide receiver may switch to a Defensive Back from one year to the next. Another senario is a player transfers from a junior college to a university and that will cause a difference in count from one year to the next. Players may also leave for the NFL draft after their Junior year and this can cause a drop in the number of players for the positions. Another thing we can look at is some positions like Punter and Kicker have far fewer players in these positions than Defensive Back or Offensive Lineman. These positions only require a few players per team as there is only one slot on the field for them and they are less likely to get injured. Where as Defensive Backs and Offensive Linemen take up multiple spots on a field and are far more likely to get injured.
```{r}
ggplot(collegedf, aes(Pos, fill = Yr, group = Yr)) +
  geom_bar(position = "dodge") +
  coord_flip()
```

Define college_teams data frame 
```{r}
college_teams <- inner_join(collegedf, basic_stats, by = c("team_name" = "College", "Player" = "Name")) 
```

The below chart shows us the colleges which have at least one or more players drafted into the NFL from 2014 onwards. The two teams with the highest number of drafted players are Michigan and Stanford tied with 7 players drafted into the NFL. This chart can give us an idea of which schools consistently send players to the NFL and can even give us an idea of how competitive they are in the NCAA. The idea to the last notion is the more players which are drafted would mean the teams have more highly skilled players which in turn could mean the team was more competitive. The toal number of players drafted between 2014 and 2017 is 2735.
```{r, eval=FALSE}
table(college_draft$was_drafted)
```

```{r, fig.height=10}
ggplot(filter(college_teams, start_year >= 2014), aes(x = team_name)) +
  geom_bar() +
  coord_cartesian(ylim=c(2,7)) +
  coord_flip() +
  theme(axis.text=element_text(size=12),
        axis.title=element_text(size=20,face="bold"))
```


#Linear Regression
### Linear Regression Model for experience
 
Using a linear model I wanted to see if we could predict experience or the number of years a player would be in the NFL. What this model does is predicts the years of experience by college. 
```{r}
basic_stats <- mutate(basic_stats, College = sub("&", " ", College, ignore.case = TRUE))
nfl_model <- lm(Experience ~ College -1, data = basic_stats)
AIC(nfl_model)
```

The texreg of the model shows the relative experience by college. 
```{r results="asis"}
broom::tidy(nfl_model) %>% top_n(5, estimate)
broom::tidy(nfl_model) %>% top_n(5, -estimate)
```


```{r}
SSE <- sum(nfl_model$residuals^2)
SSE
```
### Second Regression Model for experience

The second linear model uses weight in lbs and college to predict the experince of a player. 
```{r}
nfl_model2 <- lm(Experience ~ Weight..lbs. + College , data = basic_stats)
AIC(nfl_model2)
```

```{r}
SSE2 <- sum(nfl_model2$residuals^2)
SSE2
```

From the plot below we see that this model is predicting the heavier the player the longer they will play in the NFL. This is not an accurate model for predicting experience for a player. 
```{r}
cplot(nfl_model2, "Weight..lbs.")
```

### Third Regression Model for experience

The third linear model uses height in inches, weight in lbs, and I(Weight..lbs.^2) + Position to predict the experince of a player. 
```{r}
nfl_model3 <- lm(Experience ~ Height..inches. + Weight..lbs. + I(Weight..lbs.^2) + Position, data = basic_stats)
AIC(nfl_model3)
```

```{r}
SSE3 <- sum(nfl_model3$residuals^2)
SSE3
```
From the weight plot below we see that this model is showing players who are between 250 and 300 lbs have the longest longevity in the NFL. Above 300 lbs the players eperience starts to fall. 
From the height plot below it shows the taller the player the more experince it is expected a player will have. This is not a practical assumption similar to model 2, it's not necesarily true the taller a player is the more years a player will have in the NFL.
```{r}
cplot(nfl_model3, "Weight..lbs.")
cplot(nfl_model3, "Height..inches.")
```

From the plot below we see the predicted years if experience for positions based on the weight in lbs. I should note that a predicted value cannot be negative as a player cannot play negative time. For the defensive lineman it shows a negative to a positive predicted years of experience and has a median predicted value at 0 years of experience. From this example we gather that a DL will most likely have a short career in the NFL.
```{r}
cplot(nfl_model3, x = "Position", dx = "Weight..lbs.", ylab = "Predicted Years of Experience")
```

Create new variable predicted
```{r}
predicted <- predict(nfl_model3)
ggplot(basic_stats %>% mutate(predicted = predict(nfl_model3, basic_stats)) %>% group_by(Weight..lbs.) %>% summarise(predicted = mean(predicted, na.rm = TRUE))) + aes(x = Weight..lbs., y = predicted) + geom_line()
```

### Fourth Regression Model for experience 

The fourth linear model uses height in inches and  Weight..lbs. * Position to predict the experince of a player. 

```{r}
nfl_model4 <- lm(Experience ~ Height..inches. + Weight..lbs. * Position, data = basic_stats)
AIC(nfl_model4)
```

```{r}
SSE4 <- sum(nfl_model4$residuals^2)
SSE4
```
The below box and whiskers plot which shows experience by state. It looks like the median experience is about 3 - 4 years for most states. The third quartile is generally from 5-7 years of experience. Which means most players will have retired between 5 and 7 years in the NFL.
```{r}
boxplot(Experience~State, basic_stats)
```
From the plot below we see the predicted years if experience for different positions. I should note that a predicted value cannot be negative as a player cannot play negative time. For the center back it shows 3 to 6  years of predicted experience and is predicted at 5 years of experience. From this example we gather that a CB will most likely have a lengthy career in the NFL.
```{r}
cplot(nfl_model4, "Position")
```

### Summary of Linear Models by Experience
According to SSE the best model was weight and college with an SSE of 198610.6. However, when I used AIC it preferred the model height and weight by position with a value of 90677.07.

# Linear Model for drafting

For the first linear model to predict whether a player was drafted I used the dependent variable was_drafted and independent variables Year, Position, Games Played, and Games Started. From the table below we see the linear model draft1 Games played and Games Started are statistically significant. Games Started is more significant than Games Played. For Year variable Senior Year is statistically significant and Junior Year is almost statistically significant. The positions which are statistically significant are DL, K, RB, TE, and WR. Something to note is the prediction is based off of the DB position which may explain why DL is statistically significant and not a OL or QB.
```{r}
draft1 <- lm(was_drafted ~ Yr + Pos + GP + GS, data = college_draft)
```

```{r}
summary(draft1)
```

For the second linear model to predict whether a player was drafted I used the dependent variable was_drafted and independent variables Year, position, games played, rushing attempts, rushing net yards, rushing yards gained. From the table below a players Junior and Senior year are statistically significant to being drafted into the NFL. While a players Sophmore year is almost statistically significant.
```{r results="asis"}
draft2 <- lm(was_drafted ~ Yr + Pos + GP + Rush.Attempts + Rush.Net.Yards + Rush.YdsGained, data = college_draft)
```

```{r}
summary(draft2)
```

```{r results="asis"}
texreg(list(draft1,draft2), table = FALSE, use.packages = FALSE)
```


### Differences in the drafting rates for position
The number of drafted players per position will come down to how many slots on the field utilize that position. Punters and kickers are one of the least drafted positions because there only needs to be one of them on the field and are not utilized very frequently. This will also mean punters and kickers will be less likely to get injured so they will have longer careers. So the need to draft a kicker or punter isn't as necessary as a position like an Offensive Lineman or Defensive Lineman. These two positions will play every snap on offense or defense and they are always in the mix. For these positions injuries occur a lot more frequently and career length will be shorter. 
```{r}
ggplot(college_draft) + aes(x=Pos, fill = was_drafted) + geom_bar()
```
### Summary of Linear Model for drafting
According to RSE the better model was Yr + Pos + GP + GS with an RSE of 0.2487 on 38091 degrees of freedom. This model has an Adjusted R-squared of 0.06974 which is better than the model Yr + Pos + GP + Rush.Attempts + Rush.Net.Yards + Rush.YdsGained which has an Adjusted R-squared of 0.06529.

# Logistic Regression
Using logistic regression I will predict whether a player will be drafted into the NFL. The outcome of the prediction will be TRUE or FALSE, TRUE if the player is drafted into the NFL and FALSE if the player is not drafted. I will use a joined data set of the NFL and NCAA data sets to run the prediction on.

```{r}
set.seed(122)
split <- sample.split(college_draft$was_drafted, SplitRatio = 0.75)
```


#### create training set
```{r}
college_draftTrain <- subset(college_draft, split == TRUE)
nrow(college_draftTrain)
```

#### Run the model on Train
The subset defined below has all colleges where at least one player was drafted.
```{r}
college_draftTrain <- subset(college_draftTrain, ave(college_draftTrain$was_drafted, college_draftTrain$team_name, FUN=sum) > 0)
```

#### Build the Logistic Regression Model
I built the logistic regression model using the dependent variable was_drafted  and the independent variables games played (GP), position (Pos), year (Yr), and team_name. 
```{r}
college_draftLog <- glm(was_drafted ~ GP + Pos + Yr + team_name, family = binomial(), college_draftTrain)
summary(college_draftLog)
```

#### Build prediction of college_draftLog
Here I take the logistic regression model created above and predict the likelihood of a player being drafted into the NFL. When we look at the summary of the prediction we have a minimum chance of being drafted in to the NFL of 0% and a maximum of 68.9%.
```{r}
predict_college_draftTrain <- predict(college_draftLog, newdata = college_draftTrain, type = "response")
kable(as.matrix(summary(predict_college_draftTrain))) %>%
  kable_styling(latex_options = "striped")
```

### Average Predicted Probabilities
For all of the TRUE cases where the player was drafted there is a probability of 0.247 and all of the TRUE cases where the player didn't get drafted of 0.105. We can see we are predicting slightly higher the TRUE cases that are drafted.
```{r}
kable(tapply(predict_college_draftTrain, college_draftTrain$was_drafted,  FUN=mean)) %>%
  kable_styling(latex_options = "striped")
```

### Confusion Matrix
The below table gives us the total cases where players were predicted as True Negative, False Positive, False Negative, and True Positive. It shows the model predicted 9885 players as not being drafted correctly. There are 4669 players which the model said they would not be drafted but were drafted. The model shows 456 players which were predicted to be drafted but were not and 1591 players predicted to be drafted which were drafted. This model is biased more towards predicting palyers to not be drafted into the NFL.
```{r}
train_fnfp <- table(college_draftTrain$was_drafted, predict_college_draftTrain > mean(college_draftTrain$was_drafted))
kable(train_fnfp) %>%
  kable_styling(latex_options = "striped")
```

### Sensitivity, Specificity, and Accuracy
Sensitivity is the correct number of predicted players drafted divided by the total number of true positives and false negatives. Sensitivity measures the percentage of the actual players who were drafted correctly. The sensitivity of the model was .777, meaning 77.7% of actual positives were correctly identified.
Specificity is the correct number of predicted players not drafted by the total number of true negatives and false positives. Specificity measures the percentage of the actual players who were not drafted correctly. The specificity of the model measured 67.9% of the predictions correctly of players who were not drafted.
The accuracy of the model was .684, meaning the proportion was .684 of the predictions were correct.
```{r}
sens <- 1591/2047
spec <- 9885/14554
acc <- (9887 + 1616)/(9887 + 4862 + 447 + 1616)
kable(data.frame(Sensitivity = sens, Specificity = spec, Accuracy = acc)) %>%
  kable_styling(latex_options = "striped")
```

#### Create a Testing Set
```{r}
college_draftTest <- subset(college_draft, split == FALSE)
college_draftTest <- subset(college_draftTest, college_draftTest$team_name %in% college_draftTrain$team_name)
nrow(college_draftTest)
```

#### Test prediction on Test data set
Here I take the logistic regression model created above and predict the likelihood of a player being drafted into the NFL. When we look at the summary of the prediction we have a minimum chance of being drafted in to the NFL of 0% and a maximum of 66.2%.
```{r}
predict_Test <- predict(college_draftLog, newdata = college_draftTest, type = "response")
kable(as.matrix(summary(predict_Test))) %>%
  kable_styling(latex_options = "striped")
```

### Average Predicted Probabilities
For all of the TRUE cases where the player was drafted there is a probability of 0.246 and all of the TRUE cases where the player didn't get drafted of 0.109. We can see we are predicting slightly higher the TRUE cases that are drafted.
```{r}
kable(tapply(predict_Test, college_draftTest$was_drafted,  FUN=mean)) %>%
  kable_styling(latex_options = "striped")
```
### Confusion Matrix
The below table gives us the total cases where players were predicted as True Negative, False Positive, False Negative, and True Positive. It shows the model predicted 3242 players as not being drafted correctly. There are 1681 players which the model said they would not be drafted but were drafted. The model shows 133 players which were predicted to be drafted but were not and 549 players predicted to be drafted which were drafted. This model is biased more towards predicting palyers to not be drafted into the NFL.
```{r}
test_fnfp <- table(college_draftTest$was_drafted, predict_Test > mean(college_draftTrain$was_drafted))
kable(test_fnfp) %>%
  kable_styling(latex_options = "striped")
```

### Sensitivity, Specificity, and Accuracy
Sensitivity is the correct number of predicted players drafted by by the total number of true positives and false negatives. Sensitivity measures the percentage of the actual players who were drafted correctly. The sensitivity of the model was .804, meaning 80.4% of actual positives were correctly identified.
Specificity is the correct number of predicted players not drafted by the total number of true negatives and false positives. Specificity measures the percentage of the actual players who were not drafted correctly. The specificity of the model measured 65.8% of the predictions correctly of players who were not drafted.
The accuracy of the model was .698, meaning the proportion was .698 of the predictions were correct.
```{r}
sens2 <- 549/682
spec2 <- 3242/4923
acc2 <- (3479 + 544)/(3479 + 1593 + 144 + 544)
kable(data.frame(Sensitivity = sens2,Specificity = spec2,Accuracy = acc2)) %>%
  kable_styling(latex_options = "striped")
```


### ROC Curve, AUC, Recall & Precision
In the ROC Curve plot below it shows the true positive rate and the false positive rate. Based on the results I would like to choose a threshold value from 0.3 t0 0.2 as this threshold value range pulls the most towards the top left corner. A threshold value chosen in this range will provide the best tradeoff for the true positive and false positive rates.
A random guess for area under the curve (AUC) is 0.5. So the model created needs to perform better than a random guess. The AUC for this model is 0.797 which is a lot better than a random guess but it's not perfect. 
If the decision threshold were at .2 then the recall would be .6 and the precision would be .75.
```{r}
ROCRpred_Test <- ROCR::prediction(predict_Test, college_draftTest$was_drafted)
ROCRperf_Test <- performance(ROCRpred_Test, "tpr", "fpr")
plot(ROCRperf_Test, colorize = TRUE, print.cutoffs.at=seq(0,1,0.1), text.adj=c(-0.2,1.7))
text(.9,0,paste("AUC",round(auc(college_draftTest$was_drafted, predict_Test),3)))
```

# Logistic Regression Model 2
#### create training set
```{r}
college_draftTrain2 <- subset(college_draft, split == TRUE)
nrow(college_draftTrain2)
```

##### Run the model on Train2
The subset has all colleges where at least one player was drafted
```{r}
college_draftTrain2 <- subset(college_draftTrain2, ave(college_draftTrain2$was_drafted, college_draftTrain2$team_name, FUN=sum) > 0)
```

#### Build the Logistic Regression Model
```{r}
college_draftLog2 <- glm(was_drafted ~ Pos + GP + GS + season + team_name, family = binomial(), college_draftTrain2)
summary(college_draftLog2)
```

#### Build prediction of college_draftLog2
```{r}
predict_college_draftTrain2 <- predict(college_draftLog2, newdata = college_draftTrain2, type = "response")
kable(as.matrix(summary(predict_college_draftTrain2))) %>%
  kable_styling(latex_options = "striped")
```


### Confusion Matrix
The below table gives us the total cases where players were predicted as True Negative, False Positive, False Negative, and True Positive. It shows the model predicted 11199 players as not being drafted correctly. There are 3353 players which the model said they would not be drafted but were drafted. The model shows 405 players which were predicted to be drafted but were not and 1642 players predicted to be drafted which were drafted. This model is biased more towards predicting palyers to not be drafted into the NFL.

```{r}
train_fnfp2 <- table(college_draftTrain2$was_drafted, predict_college_draftTrain2 > mean(college_draftTrain2$was_drafted))
kable(train_fnfp2) %>%
  kable_styling(latex_options = "striped")
```


### Sensitivity, Specificity, Accuracy
Sensitivity is the correct number of predicted players drafted by by the total number of true positives and false negatives. Sensitivity measures the percentage of the actual players who were drafted correctly. The sensitivity of the model was .802, meaning 80.2% of actual positives were correctly identified.
Specificity is the correct number of predicted players not drafted by the total number of true negatives and false positives. Specificity measures the percentage of the actual players who were not drafted correctly. The specificity of the model measured 76.9% of the predictions correctly of players who were not drafted.
The accuracy of the model was .769, meaning the proportion was .769 of the predictions were correct.
```{r}
sens3 <- 1642/2047
spec3 <- 11199/14552
acc3 <- (11291 + 1651)/(11291 + 3456 + 412 + 1651)
kable(data.frame(Sensitivity = sens3, Specificity = spec3, Accuracy = acc3)) %>%
  kable_styling(latex_options = "striped")
```

### Average Predicted Probabilities
```{r}
kable(tapply(predict_college_draftTrain2, college_draftTrain2$was_drafted,  FUN=mean, na.rm = TRUE)) %>%
  kable_styling(latex_options = "striped")
```


#### create testing set
```{r}
college_draftTest2 <- subset(college_draft, split == FALSE)
nrow(college_draftTest2)
```

The subset has all colleges where at least one player was drafted in test
```{r}
college_draftTest2 <- subset(college_draftTest2, ave(college_draftTest2$was_drafted, college_draftTest2$team_name, FUN=sum) > 0)
```

#### Build test prediction of college_draftTestLog
```{r}
predict_cdTest2 <- predict(college_draftLog2, newdata = college_draftTest2, type = "response")
kable(as.matrix(summary(predict_cdTest2))) %>%
  kable_styling(latex_options = "striped")
```

### Confusion Matrix
The below table gives us the total cases where players were predicted as True Negative, False Positive, False Negative, and True Positive. It shows the model predicted 3418 players as not being drafted correctly. There are 1120 players which the model said they would not be drafted but were drafted. The model shows 155 players which were predicted to be drafted but were not and 527 players predicted to be drafted which were drafted. This model is biased more towards predicting palyers to not be drafted into the NFL.
```{r}
test_fnfp2 <- table(college_draftTest2$was_drafted, predict_cdTest2 > mean(college_draftTest2$was_drafted))
kable(test_fnfp2) %>%
  kable_styling(latex_options = "striped")
```

### Sensitivity, Specificity, and Accuracy
Sensitivity is the correct number of predicted players drafted by by the total number of true positives and false negatives. Sensitivity measures the percentage of the actual players who were drafted correctly. The sensitivity of the model was .772, meaning 77.2% of actual positives were correctly identified.
Specificity is the correct number of predicted players not drafted by the total number of true negatives and false positives. Specificity measures the percentage of the actual players who were not drafted correctly. The specificity of the model measured 75.3% of the predictions correctly of players who were not drafted.
The accuracy of the model was .769, meaning the proportion was .769 of the predictions were correct.
```{r}
sens4 <- 527/682
spec4 <- 3418/4538
acc4 <- (3811 + 558)/(3811 + 1181 + 130 + 558)
kable(data.frame(Sensitivity = sens4, Specificity = spec4, Accuracy = acc4)) %>%
  kable_styling(latex_options = "striped")
```


### Average Predicted Probabilities on Test
For all of the TRUE cases where the player was drafted there is a probability of 0.32 and all of the TRUE cases where the player didn't get drafted of 0.1. We can see we are predicting slightly higher the TRUE cases that are drafted.
```{r}
tapply(predict_cdTest2, college_draftTest2$was_drafted, FUN=mean) %>% data.frame(was_drafted = .) %>% kable() %>% kable_styling(latex_options = "striped")
```


### ROC Curve, AUC, and Recall and Precision
In the ROC Curve plot below it shows the true positive rate and the false positive rate. Based on the results I would like to choose a threshold value from 0.4 to 0.2 as this threshold value range pulls the most towards the top left corner. A threshold value chosen in this range will provide the best tradeoff for the true positive and false positive rates.
A random guess for area under the curve (AUC) is 0.5. So the model created needs to perform better than a random guess. Let's see if we can improve upon the first model which had an AUC of 0.797. The AUC for this model is 0.846 which is better than our previous model and a lot better than a random guess. 
If the decision threshold were at .3 then the recall would be .5 and the precision would be 5/6. 
```{r}
ROCRpred_Test2 <- ROCR::prediction(predict_cdTest2, college_draftTest2$was_drafted)
ROCRperf_Test2 <- performance(ROCRpred_Test2, "tpr", "fpr")
plot(ROCRperf_Test2, colorize = TRUE, print.cutoffs.at=seq(0,1,0.1), text.adj=c(-0.2,1.7))
text(.9,0,paste("AUC",round(auc(college_draftTest2$was_drafted, predict_cdTest2),3)))
```


### ROC plots stacked
From the plots below we can see the second logistic regression ROC plot is far superior as the curve pulls to the top left even more. The AUC for the second plot is 0.847 compared to the first is 0.797, based on these models the second will be more accurate no matter what threshold you use.
```{r}
plot(ROCRperf_Test, col = 4, lty = 1, main = "ROC")
plot(ROCRperf_Test2, col = 2, lty = 2, add = TRUE)
text(0.9,0,paste("AUC",round(auc(college_draftTest$was_drafted, predict_Test),3)))
text(0.9,0.1,paste("AUC",round(auc(college_draftTest2$was_drafted, predict_cdTest2),3)))
```

## Appendix
Plot of nfl_model
```{r}
plot(nfl_model)
```

Plot of nfl_model2
```{r}
plot(nfl_model2)
```

Plot of nfl_model3
```{r}
plot(nfl_model3)
```